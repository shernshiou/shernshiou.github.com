<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Computing | Shern Shiou]]></title>
  <link href="http://tranquil-bastion-2708.herokuapp.com//blog/categories/computing/atom.xml" rel="self"/>
  <link href="http://tranquil-bastion-2708.herokuapp.com//"/>
  <updated>2012-08-21T01:04:10+08:00</updated>
  <id>http://tranquil-bastion-2708.herokuapp.com//</id>
  <author>
    <name><![CDATA[shernshiou]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Information Theory on Images]]></title>
    <link href="http://tranquil-bastion-2708.herokuapp.com//blog/2011/05/26/information-theory-on-images/"/>
    <updated>2011-05-26T00:00:00+08:00</updated>
    <id>http://tranquil-bastion-2708.herokuapp.com//blog/2011/05/26/information-theory-on-images</id>
    <content type="html"><![CDATA[<p>In the past, I have always encountered these questions while doing my research. To truly emulate human vision perception in computer vision, I need to understand how the mechanism works. These questions form the fundamental mechanism of human vision. Therefore, I decided to compute several images to proof my believe. My main hypothesis is human vision is represented in HSV colour model rather than RGB colour model. To proof this, I will be using basic Information Theory to compute the information composition in an single image both RGB and HSV.</p>

<h3 id="information-theory">Information Theory</h3>

<script type="math/tex; mode=display">
\begin{equation} H(X) = -\sum_{x \in \mathcal{X}} p(x) \log_b p(x). \end{equation}
</script>

<h6 id="shannons-entropy-equation">Shannonâ€™s Entropy Equation</h6>

<p>The basic Shannon Entropy will be used to compute each individual plane in an image. This entropy is used to measure the unpredictability. The easier to predict, the lower the entropy it has. In this case, I also made an assumption that entropy directly relate to the information contained / encoded within. If you need detail description on Shannon Entropy, head over to <a href="http://en.wikipedia.org/wiki/Entropy_(information_theory)">http://en.wikipedia.org/wiki/Entropy_(information_theory)</a> which contains fairly understandable explanation.</p>

<h3 id="methods">Methods</h3>
<p>A set of 20 various images from grayscale to single colour, from human and non-human images are collected. Entropy will be computed on grayscale mode, Red plane, Blue plane, Green plane as well as Hue plane, Saturation plane and Intensity.</p>

<h3 id="results-and-explanation">Results and Explanation</h3>
<p><img class="center" src="/images/gallery/entropy_result.png" width="483" height="431" title="Result Table" >
As expected RGB plane has pretty similar entropy in every images. If one of the plane has low entropy, both the plane will follow including the grayscale version of the image. On the other hand, HSV has a pretty interesting results. Averagely, Intensity plane has higher entropy than the other Hue and Saturation. In the event of grayscale image (note Image 17 and 18), Intensity contain entropy but not the other two.</p>

<h3 id="conclusion">Conclusion</h3>
<ol>
  <li>Intensity planes contain more information. Therefore, we are able to perceive an image from only the intensity plane.</li>
  <li>Single colour image does has information but when converted to HSV plane, it represents 0 entropy in every plane.</li>
  <li>Human vision is closer to HSV than RGB. Notes: Cone cell in retina</li>
</ol>

<h3 id="references">References</h3>
<ol>
  <li>Wikipedia on Shannon Entropy <a href="http://en.wikipedia.org/wiki/Entropy_(information_theory)">http://en.wikipedia.org/wiki/Entropy_(information_theory)</a></li>
  <li>Beginner explanation of how entropy is applied in classification <a href="http://stackoverflow.com/questions/1859554/what-is-entropy-and-information-gain">http://stackoverflow.com/questions/1859554/what-is-entropy-and-information-gain</a></li>
  <li>Kodak Lossless Image Suite used in Sample Images <a href="http://r0k.us/graphics/kodak/">http://r0k.us/graphics/kodak/</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data Engineering]]></title>
    <link href="http://tranquil-bastion-2708.herokuapp.com//blog/2011/05/11/data-engineering/"/>
    <updated>2011-05-11T00:00:00+08:00</updated>
    <id>http://tranquil-bastion-2708.herokuapp.com//blog/2011/05/11/data-engineering</id>
    <content type="html"><![CDATA[<p>Since the invention of computing devices, we have seen numerous data explosions. Reasons? Storage devices are getting cheaper but the storage ability is growing. It is now easier to share information especially through the cloud. Connectivity between human and non-human became more robust and sophisticated. Devices are made widely available. But there is a big problem here. Although we have expected the growth of data exponentially, but there are little ways developed for us to manage and fully make used of the data available for the greater benefit.</p>

<p><img class="center" src="http://farm6.static.flickr.com/5023/5693449522_57353dd78a_o.png" width="1086" height="769" title="Bin Laden death diaspora by SocialFlow" ></p>

<h6 id="bin-laden-death-diaspora-by-socialflow">Bin Laden Death Diaspora by SocialFlow</h6>

<h3 id="what-is-data-engineering">What is Data Engineering?</h3>
<p>We need people who are expert in managing the data. The experts may not be of computer science background because data engineering has been part of many profession. For example, statistician/mathematician often are good in explaining huge amount of data while neurologists have the knowledge on the data management inside our human brain. Their job scope should include more than choosing the right storage to preserve the data, system to organize the data, technology to retrieve the data. Data engineer need to churn out useful information from the data collection, explains the phenomenon and understand their nature. Data engineering will be the trend in the future while Computer Science will aid in providing tools to increase the performance of data engineer especially Machine Learning.</p>
]]></content>
  </entry>
  
</feed>
